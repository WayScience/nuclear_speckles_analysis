{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "kVG1q9x0D6"
      },
      "source": [
        "# Predict GOLD Stain from DAPI (Fnet)\n",
        "The 2d fnet architecture (https://doi.org/10.1038/s41592-018-0111-2) is trained to predict the GOLD stain from cropped DAPI Nuclei Images.\n",
        "This model was trained on a similar task, therefore, we are interested in model's performance when trained on our task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "hiLBvSISaw"
      },
      "source": [
        "import pathlib\n",
        "import random\n",
        "import sys\n",
        "from collections import defaultdict\n",
        "\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "import mlflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "Meri0joHnI"
      },
      "source": [
        "## Find the root of the git repo on the host system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Ko16YFvQXV"
      },
      "source": [
        "# Get the current working directory\n",
        "cwd = pathlib.Path.cwd()\n",
        "\n",
        "if (cwd / \".git\").is_dir():\n",
        "    root_dir = cwd\n",
        "\n",
        "else:\n",
        "    root_dir = None\n",
        "    for parent in cwd.parents:\n",
        "        if (parent / \".git\").is_dir():\n",
        "            root_dir = parent\n",
        "            break\n",
        "\n",
        "# Check if a Git root directory was found\n",
        "if root_dir is None:\n",
        "    raise FileNotFoundError(\"No Git root directory found.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "vGuEzAxPyF"
      },
      "source": [
        "## Custom Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "AN1PVs3hBQ"
      },
      "source": [
        "sys.path.append(str((root_dir / \"1.develop_vision_models\").resolve(strict=True)))\n",
        "\n",
        "from ImageDataset import ImageDataset\n",
        "from models.fnet_nn_2d import Net\n",
        "from ModelTrainer import ModelTrainer\n",
        "from transforms.CropNPixels import CropNPixels\n",
        "from transforms.StandardScaler import StandardScaler"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "ZDjx5NhMh5"
      },
      "source": [
        "## Set random seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "goD9xIS6sd"
      },
      "source": [
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "mlflow.log_param(\"random_seed\", 0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "dbCREcNBCC"
      },
      "source": [
        "# Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "1EyjCcnIdZ"
      },
      "source": [
        "# Nuclei crops path of treated nuclei in the Dapi channel with all original pixel values\n",
        "treated_dapi_crops = root_dir / \"vision_nuclear_speckle_prediction/treated_nuclei_dapi_crops\"\n",
        "\n",
        "# Nuclei crops path of nuclei in the Gold channel with all original pixel values\n",
        "gold_crops = root_dir / \"vision_nuclear_speckle_prediction/gold_cropped_nuclei\"\n",
        "\n",
        "# Paths to original nuclear speckle data\n",
        "data_dir = root_dir / \"nuclear_speckles_data\"\n",
        "nuclear_mask_dir = (data_dir / \"Nuclear_masks\").resolve(strict=True)\n",
        "sc_profiles_path = list((data_dir / \"Preprocessed_data/single_cell_profiles\").resolve(strict=True).glob(\"*feature_selected*.parquet\"))\n",
        "\n",
        "# Load single-cell profile data\n",
        "scdfs = [pd.read_parquet(sc_path) for sc_path in sc_profiles_path if sc_path.is_file()]\n",
        "scdfs = pd.concat(scdfs, axis=0).reset_index(drop=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "SCnVToH5O1"
      },
      "source": [
        "# Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "8ufd624Ycq"
      },
      "source": [
        "figure_path = pathlib.Path(\"fnet_validation_images_temp\")\n",
        "figure_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "metrics_path = pathlib.Path(\"metrics\")\n",
        "metrics_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model_path = pathlib.Path(\"model\")\n",
        "model_path.mkdir(parents=True, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "HVINHVNqNE"
      },
      "source": [
        "description = \"Here we leverage the 2d fnet architecture in https://doi.org/10.1038/s41592-018-0111-2 to predict the GOLD stain from cropped DAPI Nuclei Images. We retain all pixel values in the cropped images\"\n",
        "mlflow.set_tag(\"mlflow.note.content\", description)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "79aCdZVnr1"
      },
      "source": [
        "# Image Generation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "u1rAXJ2oS2"
      },
      "source": [
        "def format_img(_tensor_img):\n",
        "    \"\"\"Reshapes an image and rescales pixel values from the StandardScaler transform.\"\"\"\n",
        "\n",
        "    mean = trainer.val_dataset.dataset.input_transform[0].mean\n",
        "    std = trainer.val_dataset.dataset.input_transform[0].std\n",
        "\n",
        "    return (torch.squeeze(_tensor_img) * std + mean).to(torch.uint16).cpu().numpy()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "CxqLJC1H7k"
      },
      "source": [
        "def evaluate_and_format_imgs(_input, _target):\n",
        "\n",
        "    single_input = input.unsqueeze(1).to(device)\n",
        "    single_target = target.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Forward Pass\n",
        "        output = model(single_input)\n",
        "\n",
        "    return format_img(single_input), format_img(single_target), format_img(output)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "1aeIZilTQ4"
      },
      "source": [
        "# Initialize and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "hOpgm7TTzF"
      },
      "source": [
        "transforms = A.Compose([\n",
        "    StandardScaler(_always_apply=True),\n",
        "    CropNPixels(_pixel_count=1, _always_apply=True)\n",
        "])\n",
        "\n",
        "img_dataset = ImageDataset(\n",
        "    _input_dir=treated_dapi_crops,\n",
        "    _target_dir=gold_crops,\n",
        "    _input_transform=transforms,\n",
        "    _target_transform=transforms\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "RFhdisqTYz"
      },
      "source": [
        "model = Net()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "k5VvaO0rJb"
      },
      "source": [
        "optim_params = {\n",
        "    \"lr\": 1e-3,\n",
        "    \"betas\": (0.5, 0.999)\n",
        "}\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    **optim_params\n",
        ")\n",
        "\n",
        "mlflow.log_param(\"Optimizer\", \"ADAM\")\n",
        "mlflow.log_params(optim_params)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "gCGJH6f2N0"
      },
      "source": [
        "# These keys will be in the names of the logged losses\n",
        "tracked_losses = {\n",
        "    \"mse loss\": nn.MSELoss(),\n",
        "    \"mae loss\": nn.L1Loss()\n",
        "}\n",
        "\n",
        "backprop_loss_name = \"mae loss\"\n",
        "\n",
        "mlflow.log_param(\"Training Loss\", backprop_loss_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "yuahqaK6bO"
      },
      "source": [
        "trainer_params = {\n",
        "    \"_batch_size\": 32,\n",
        "    \"_epochs\": 2,\n",
        "    \"_patience\": 1\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ysdNFUJpaV"
      },
      "source": [
        "trainer = ModelTrainer(\n",
        "    _model=model,\n",
        "    _image_dataset=img_dataset,\n",
        "    _optimizer=optimizer,\n",
        "    _tracked_losses=tracked_losses,\n",
        "    _backprop_loss_name=backprop_loss_name,\n",
        "    **trainer_params\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "q0gMPtxZX6"
      },
      "source": [
        "trainer.train()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "5L32l3Q5aZ"
      },
      "source": [
        "# Generate Images\n",
        "Evaluate the model by generating the same number of example images for each siRNA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "9jlZLKlJ6p"
      },
      "source": [
        "example_images_per_sirna = 10\n",
        "max_pixel_val = 2**16 - 1\n",
        "\n",
        "sirna_img_counts = {sirna: 0 for sirna in scdfs.loc[scdfs[\"Metadata_Condition\"] != \"untreated\"][\"Metadata_Condition\"].unique()}\n",
        "i = 0\n",
        "\n",
        "for input, target in iter(trainer.val_dataset):\n",
        "\n",
        "    img_name = trainer.val_dataset.dataset.input_name\n",
        "    img_name = img_name.replace(\"_illumcorrect.tiff\", \"\")\n",
        "\n",
        "    cell_id = img_name.split(\"_\")[0]\n",
        "    sirna = scdfs.loc[int(cell_id)][\"Metadata_Condition\"]\n",
        "\n",
        "    if sirna not in list(sirna_img_counts.keys()):\n",
        "        continue\n",
        "\n",
        "    input, target, output = evaluate_and_format_imgs(input, target)\n",
        "\n",
        "    titles = ['DAPI Image', 'Predicted GOLD Image', 'Target GOLD Image']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    fig.suptitle(f\"{img_name}\", fontsize=16)\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.3, hspace=0)  # Adjust `wspace` if titles overlap\n",
        "\n",
        "    axes[0].imshow(input, cmap=\"grey\", vmin=0, vmax=max_pixel_val)\n",
        "    axes[0].axis('off')\n",
        "    axes[0].set_title(titles[0], fontsize=14)\n",
        "\n",
        "    axes[1].imshow(output, cmap=\"grey\", vmin=0, vmax=max_pixel_val)\n",
        "    axes[1].axis('off')\n",
        "    axes[1].set_title(titles[1], fontsize=14)\n",
        "\n",
        "    axes[2].imshow(target, cmap=\"grey\", vmin=0, vmax=max_pixel_val)\n",
        "    axes[2].axis('off')\n",
        "    axes[2].set_title(titles[2], fontsize=14)\n",
        "\n",
        "    plt.savefig(figure_path / f\"{img_name}.png\", bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "    sirna_img_counts[sirna] += 1\n",
        "\n",
        "    if sirna_img_counts[sirna] >= example_images_per_sirna:\n",
        "        sirna_img_counts.pop(sirna)\n",
        "\n",
        "        if not sirna_img_counts:\n",
        "            break"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "torch.Size([1, 1, 64, 64])\n"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "acR8M5ntCA"
      },
      "source": [
        "# Log Metrics and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "uTLac1sMYT"
      },
      "source": [
        "client = mlflow.MlflowClient()\n",
        "\n",
        "run_id = mlflow.active_run().info.run_id\n",
        "run = client.get_run(run_id)\n",
        "\n",
        "metrics_per_epoch = defaultdict(list)\n",
        "\n",
        "for metric_name in run.data.metrics.keys():\n",
        "    metric_history = client.get_metric_history(run_id=run_id, key=metric_name)\n",
        "    for metric in metric_history:\n",
        "        metrics_per_epoch[metric_name].append(metric.value)\n",
        "\n",
        "metricsdf = pd.DataFrame(metrics_per_epoch)\n",
        "metricsdf[\"epoch\"] = np.arange(metricsdf.shape[0])\n",
        "metricsdf.to_csv(metrics_path / \"fnet_metrics_per_epoch.csv\", index=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "c3SsRLYFxN"
      },
      "source": [
        "mlflow.pytorch.log_model(pytorch_model=model.cpu(), artifact_path=\"model\", conda_env=str(root_dir / \"environment.yml\"))\n",
        "\n",
        "# Save model for github\n",
        "torch.save(model.state_dict(), model_path / \"fnet_model_states.pth\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "UNet(\n  (inc): DoubleConv(\n    (double_conv): Sequential(\n      (0): Conv2d(1, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(66, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (down1): Down(\n    (maxpool_conv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv2d(66, 132, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(132, 132, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down2): Down(\n    (maxpool_conv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv2d(132, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(264, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down3): Down(\n    (maxpool_conv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv2d(264, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down4): Down(\n    (maxpool_conv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv2d(528, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(1056, 1056, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (up1): Up(\n    (up): ConvTranspose2d(1056, 528, kernel_size=(2, 2), stride=(2, 2))\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv2d(1056, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up2): Up(\n    (up): ConvTranspose2d(528, 264, kernel_size=(2, 2), stride=(2, 2))\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv2d(528, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(264, 264, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up3): Up(\n    (up): ConvTranspose2d(264, 132, kernel_size=(2, 2), stride=(2, 2))\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv2d(264, 132, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(132, 132, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up4): Up(\n    (up): ConvTranspose2d(132, 66, kernel_size=(2, 2), stride=(2, 2))\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv2d(132, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(66, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (outc): OutConv(\n    (conv): Conv2d(66, 1, kernel_size=(1, 1), stride=(1, 1))\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}