{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "4AA77kNCKm"
   },
   "source": [
    "# Evaluate Vision Models\n",
    "Here, the best vision models, thus far, are evaluated according to four metrics on both the training and validation datasets:\n",
    "L1 Loss, L2 Loss, PSNR, and SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:36:51.717436Z",
     "iopub.status.busy": "2024-12-11T20:36:51.717341Z",
     "iopub.status.idle": "2024-12-11T20:36:53.311739Z",
     "shell.execute_reply": "2024-12-11T20:36:53.311310Z"
    },
    "jukit_cell_id": "hiLBvSISaw"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pathlib\n",
    "import random\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import albumentations as A\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "Meri0joHnI"
   },
   "source": [
    "## Find the root of the git repo on the host system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:36:53.313986Z",
     "iopub.status.busy": "2024-12-11T20:36:53.313661Z",
     "iopub.status.idle": "2024-12-11T20:36:53.316531Z",
     "shell.execute_reply": "2024-12-11T20:36:53.316197Z"
    },
    "jukit_cell_id": "Ko16YFvQXV"
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "\n",
    "# Check if a Git root directory was found\n",
    "if root_dir is None:\n",
    "    raise FileNotFoundError(\"No Git root directory found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "vGuEzAxPyF"
   },
   "source": [
    "## Custom Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:36:53.318105Z",
     "iopub.status.busy": "2024-12-11T20:36:53.317997Z",
     "iopub.status.idle": "2024-12-11T20:36:53.337575Z",
     "shell.execute_reply": "2024-12-11T20:36:53.337177Z"
    },
    "jukit_cell_id": "RTGYNW7JLL"
   },
   "outputs": [],
   "source": [
    "sys.path.append(str((root_dir / \"1.develop_vision_models\").resolve(strict=True)))\n",
    "sys.path.append(str((root_dir / \"1.develop_vision_models/losses\").resolve(strict=True)))\n",
    "sys.path.append(str((root_dir / \"1.develop_vision_models/models\").resolve(strict=True)))\n",
    "\n",
    "from datasets.ImageDataset import ImageDataset\n",
    "from L2Loss import L2Loss\n",
    "from losses.L1Loss import L1Loss\n",
    "from PSNR import PSNR\n",
    "from SSIM import SSIM\n",
    "from transforms.CropNPixels import CropNPixels\n",
    "from transforms.MinMaxNormalize import MinMaxNormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "ZDjx5NhMh5"
   },
   "source": [
    "## Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:36:53.339852Z",
     "iopub.status.busy": "2024-12-11T20:36:53.339723Z",
     "iopub.status.idle": "2024-12-11T20:36:53.372006Z",
     "shell.execute_reply": "2024-12-11T20:36:53.371749Z"
    },
    "jukit_cell_id": "goD9xIS6sd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "mlflow.log_param(\"random_seed\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "dbCREcNBCC"
   },
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:36:53.403175Z",
     "iopub.status.busy": "2024-12-11T20:36:53.403040Z",
     "iopub.status.idle": "2024-12-11T20:36:53.408206Z",
     "shell.execute_reply": "2024-12-11T20:36:53.407970Z"
    },
    "jukit_cell_id": "2hSr3QFUwp"
   },
   "outputs": [],
   "source": [
    "# Nuclei crops path of treated nuclei in the Dapi channel with all original pixel values\n",
    "treated_dapi_crops = (\n",
    "    root_dir\n",
    "    / \"vision_nuclear_speckle_prediction/treated_nuclei_dapi_crops_same_background\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "# Nuclei crops path of nuclei in the Gold channel with all original pixel values\n",
    "gold_crops = (\n",
    "    root_dir / \"vision_nuclear_speckle_prediction/gold_cropped_nuclei_same_background\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "# Contains model metadata\n",
    "model_manifestdf = pd.read_csv(\"model_manifest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "SCnVToH5O1"
   },
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:36:53.409777Z",
     "iopub.status.busy": "2024-12-11T20:36:53.409685Z",
     "iopub.status.idle": "2024-12-11T20:36:53.411349Z",
     "shell.execute_reply": "2024-12-11T20:36:53.411117Z"
    },
    "jukit_cell_id": "tf1RlhXNwo"
   },
   "outputs": [],
   "source": [
    "metrics_path = pathlib.Path(\"model_metrics\")\n",
    "metrics_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "5TaDZfsCpl"
   },
   "source": [
    "# Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:36:53.413091Z",
     "iopub.status.busy": "2024-12-11T20:36:53.412993Z",
     "iopub.status.idle": "2024-12-11T20:48:00.653697Z",
     "shell.execute_reply": "2024-12-11T20:48:00.653322Z"
    },
    "jukit_cell_id": "hOpgm7TTzF"
   },
   "outputs": [],
   "source": [
    "loss_funcs = {\n",
    "    \"l1_loss\": L1Loss(_metric_name=\"l1_loss\"),\n",
    "    \"l2_loss\": L2Loss(_metric_name=\"l2_loss\"),\n",
    "    \"psnr\": PSNR(_metric_name=\"psnr\"),\n",
    "    \"ssim\": SSIM(_metric_name=\"ssim\"),\n",
    "}\n",
    "\n",
    "losses = defaultdict(list)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Iterate through best models\n",
    "for _, model_metadata in model_manifestdf.iterrows():\n",
    "\n",
    "    if \"fnet\" in model_metadata[\"model_name\"]:\n",
    "\n",
    "        input_transforms = A.Compose(\n",
    "            [\n",
    "                MinMaxNormalize(_normalization_factor=(2**16) - 1, _always_apply=True),\n",
    "                CropNPixels(_pixel_count=1, _always_apply=True),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    else:\n",
    "\n",
    "        input_transforms = A.Compose(\n",
    "            [\n",
    "                MinMaxNormalize(_normalization_factor=(2**16) - 1, _always_apply=True),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    target_transforms = copy.deepcopy(input_transforms)\n",
    "\n",
    "    img_dataset = ImageDataset(\n",
    "        _input_dir=treated_dapi_crops,\n",
    "        _target_dir=gold_crops,\n",
    "        _input_transform=input_transforms,\n",
    "        _target_transform=target_transforms,\n",
    "    )\n",
    "\n",
    "    # Same splitting procedure as in model trainers\n",
    "    train_size = int(0.7 * len(img_dataset))\n",
    "    val_size = int(0.15 * len(img_dataset))\n",
    "    test_size = len(img_dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, _ = random_split(\n",
    "        img_dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        generator_model = (\n",
    "            mlflow.pytorch.load_model(model_metadata[\"model_path\"]).eval().to(device)\n",
    "        )\n",
    "\n",
    "        val_metric_counts = defaultdict(float)\n",
    "        train_metric_counts = defaultdict(float)\n",
    "\n",
    "        for input, target in val_dataset:\n",
    "\n",
    "            # Format target and input images\n",
    "            target = target.unsqueeze(0).to(device)\n",
    "            output = generator_model(input.unsqueeze(0).to(device))\n",
    "\n",
    "            # Accumulate losses\n",
    "            for loss_name, loss_func in loss_funcs.items():\n",
    "                val_metric_counts[loss_name] += loss_func(\n",
    "                    _generated_outputs=output, _targets=target\n",
    "                )\n",
    "\n",
    "        for input, target in train_dataset:\n",
    "\n",
    "            target = target.unsqueeze(0).to(device)\n",
    "            output = generator_model(input.unsqueeze(0).to(device))\n",
    "\n",
    "            for loss_name, loss_func in loss_funcs.items():\n",
    "                train_metric_counts[loss_name] += loss_func(\n",
    "                    _generated_outputs=output, _targets=target\n",
    "                )\n",
    "\n",
    "        # Create Tidy format\n",
    "        losses[\"model_name\"].append(model_metadata[\"model_name\"])\n",
    "        losses[\"model_name\"].append(model_metadata[\"model_name\"])\n",
    "        losses[\"datasplit\"].append(\"training\")\n",
    "        losses[\"datasplit\"].append(\"validation\")\n",
    "\n",
    "        # Normalize Losses\n",
    "        for loss_name, loss_func in loss_funcs.items():\n",
    "            losses[loss_name].append(\n",
    "                train_metric_counts[loss_name].item() / len(train_dataset)\n",
    "            )\n",
    "            losses[loss_name].append(\n",
    "                val_metric_counts[loss_name].item() / len(val_dataset)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:48:00.655919Z",
     "iopub.status.busy": "2024-12-11T20:48:00.655781Z",
     "iopub.status.idle": "2024-12-11T20:48:00.664158Z",
     "shell.execute_reply": "2024-12-11T20:48:00.663916Z"
    },
    "jukit_cell_id": "bwF17818lw"
   },
   "outputs": [],
   "source": [
    "lossdf = pd.DataFrame(losses)\n",
    "lossdf.to_csv(metrics_path / \"best_model_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T20:48:00.665913Z",
     "iopub.status.busy": "2024-12-11T20:48:00.665822Z",
     "iopub.status.idle": "2024-12-11T20:48:00.671298Z",
     "shell.execute_reply": "2024-12-11T20:48:00.671065Z"
    },
    "jukit_cell_id": "qiKzCTm57t"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>datasplit</th>\n",
       "      <th>l1_loss</th>\n",
       "      <th>l2_loss</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unconditional_pix2pix_unchanged_background</td>\n",
       "      <td>training</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>44.838643</td>\n",
       "      <td>1.648817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unconditional_pix2pix_unchanged_background</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>44.833385</td>\n",
       "      <td>1.656627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fnet_unchanged_background_standard_scalar</td>\n",
       "      <td>training</td>\n",
       "      <td>0.260201</td>\n",
       "      <td>0.092391</td>\n",
       "      <td>11.097554</td>\n",
       "      <td>0.143274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fnet_unchanged_background_standard_scalar</td>\n",
       "      <td>validation</td>\n",
       "      <td>0.260121</td>\n",
       "      <td>0.092235</td>\n",
       "      <td>11.102606</td>\n",
       "      <td>0.141958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fnet_unchanged_background_min_max_normalized</td>\n",
       "      <td>training</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>42.261989</td>\n",
       "      <td>1.600845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model_name   datasplit   l1_loss  \\\n",
       "0    unconditional_pix2pix_unchanged_background    training  0.003431   \n",
       "1    unconditional_pix2pix_unchanged_background  validation  0.003428   \n",
       "2     fnet_unchanged_background_standard_scalar    training  0.260201   \n",
       "3     fnet_unchanged_background_standard_scalar  validation  0.260121   \n",
       "4  fnet_unchanged_background_min_max_normalized    training  0.004981   \n",
       "\n",
       "    l2_loss       psnr      ssim  \n",
       "0  0.000073  44.838643  1.648817  \n",
       "1  0.000072  44.833385  1.656627  \n",
       "2  0.092391  11.097554  0.143274  \n",
       "3  0.092235  11.102606  0.141958  \n",
       "4  0.000118  42.261989  1.600845  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossdf.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
