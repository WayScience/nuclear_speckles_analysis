{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Train ElasticNet model to predict each A647 and GOLD feature using the nuclear features\n",
                "\n",
                "In this notebook, we split the features into each group for nuclear speckle or nucleus and then train a regression model per nuclear speckle feature using the nuclear features to predict it.\n",
                "\n",
                "We are looking to find the best nuclear speckle feature that can be predicted using nucleus features."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pathlib\n",
                "import sys\n",
                "import warnings\n",
                "\n",
                "import yaml\n",
                "import joblib\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.linear_model import ElasticNet\n",
                "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Ignore the ConvergenceWarnings (only thing that will work \ud83d\ude43)\n",
                "if not sys.warnoptions:\n",
                "    warnings.simplefilter(\"ignore\")\n",
                "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set paths and random seed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set numpy seed to make sure any random operations performs are reproducible\n",
                "np.random.seed(0)\n",
                "\n",
                "# Directory for models to be outputted\n",
                "model_dir = pathlib.Path(\"./models\")\n",
                "model_dir.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "# Make specific folders in model dir for each model type\n",
                "final_dir = model_dir / \"final\"\n",
                "final_dir.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "shuffled_dir = model_dir / \"shuffled_baseline\"\n",
                "shuffled_dir.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "all_features_dir = model_dir / \"all_features\"\n",
                "all_features_dir.mkdir(exist_ok=True, parents=True)\n",
                "\n",
                "# load in training data\n",
                "training_df = pd.read_parquet(pathlib.Path(\"./data/training_data.parquet\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Categorize the features as nuclear speckle (A647 or GOLD) or nucleus (DAPI) to use for model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Column names saved to /home/jenna/nuclear_speckles_analysis/1.regression_modelling/features_dict.yml\n",
                        "Nucleus Features: 225\n",
                        "A647 Features: 170\n",
                        "Gold Features: 170\n"
                    ]
                }
            ],
            "source": [
                "# Initialize lists to store column names for each feature group\n",
                "nucleus_features = []\n",
                "a647_features = []\n",
                "gold_features = []\n",
                "\n",
                "# Iterate over column names to categorize them\n",
                "for column in training_df.columns:\n",
                "    if not column.startswith(\"Metadata_\"):  # Only look at feature columns\n",
                "        parts = column.split(\"_\")\n",
                "\n",
                "        if \"Correlation\" in parts[1]:  # Check if it's a correlation feature\n",
                "            if \"DAPI\" in column:  # If DAPI is present in a correlation feature\n",
                "                if len(parts) > 4 and (\"A647\" in parts[3] or \"A647\" in parts[4]):\n",
                "                    a647_features.append(column)\n",
                "                elif len(parts) > 4 and (\"GOLD\" in parts[3] or \"GOLD\" in parts[4]):\n",
                "                    gold_features.append(column)\n",
                "            else:  # No DAPI in correlation feature, check only 4th part\n",
                "                if len(parts) > 3 and \"A647\" in parts[3]:\n",
                "                    a647_features.append(column)\n",
                "                elif len(parts) > 3 and \"GOLD\" in parts[3]:\n",
                "                    gold_features.append(column)\n",
                "        else:  # Non-correlation features\n",
                "            if len(parts) > 4 and \"Location\" in parts[1]:  # If it's a Location feature\n",
                "                if parts[4] == \"DAPI\":\n",
                "                    nucleus_features.append(column)\n",
                "                elif parts[4] == \"A647\":\n",
                "                    a647_features.append(column)\n",
                "                elif parts[4] == \"GOLD\":\n",
                "                    gold_features.append(column)\n",
                "            elif len(parts) > 3 and \"DAPI\" in parts[3]:\n",
                "                nucleus_features.append(column)\n",
                "            elif len(parts) > 3 and \"A647\" in parts[3]:\n",
                "                a647_features.append(column)\n",
                "            elif len(parts) > 3 and \"GOLD\" in parts[3]:\n",
                "                gold_features.append(column)\n",
                "            else:\n",
                "                nucleus_features.append(column)  # Default to nucleus_features\n",
                "\n",
                "\n",
                "# Prepare X data for with all nucleus features\n",
                "X = training_df[nucleus_features]\n",
                "\n",
                "# Generate shuffled data for the shuffled models to use (only do this once)\n",
                "X_shuffled = X.copy()\n",
                "for col in X_shuffled.columns:\n",
                "    np.random.shuffle(X_shuffled[col].values)  # Shuffle values in place, independently\n",
                "\n",
                "# Organize the column names into a dictionary\n",
                "features_dict = {\n",
                "    \"nucleus_features\": nucleus_features,\n",
                "    \"a647_features\": a647_features,\n",
                "    \"gold_features\": gold_features,\n",
                "}\n",
                "\n",
                "# Define the path to save the YAML file\n",
                "yaml_file_path = pathlib.Path(\"./features_dict.yml\").resolve()\n",
                "\n",
                "# Save the dictionary as a YAML file\n",
                "with open(yaml_file_path, \"w\") as yaml_file:\n",
                "    yaml.dump(features_dict, yaml_file, default_flow_style=False)\n",
                "\n",
                "print(f\"Column names saved to {yaml_file_path}\")\n",
                "\n",
                "# Print the lists to verify\n",
                "print(f\"Nucleus Features: {len(nucleus_features)}\")\n",
                "print(f\"A647 Features: {len(a647_features)}\")\n",
                "print(f\"Gold Features: {len(gold_features)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set hyperparameter parameters and search space"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set folds for k-fold cross-validation\n",
                "k_folds = KFold(n_splits=5, shuffle=True, random_state=0)\n",
                "\n",
                "# Set ElasticNet regression model parameters\n",
                "elasticnet_params = {\n",
                "    \"alpha\": 1.0,  # Equivalent to 'C' in LogisticRegression, but in reverse\n",
                "    \"l1_ratio\": 0.5,  # Mixture of L1 and L2 regularization\n",
                "    \"max_iter\": 10,\n",
                "    \"random_state\": 0,\n",
                "}\n",
                "\n",
                "# Define the hyperparameter search space for RandomizedSearchCV\n",
                "param_dist = {\n",
                "    \"alpha\": np.logspace(-3, 3, 7),  # Regularization strength\n",
                "    \"l1_ratio\": np.linspace(0, 1, 11),  # Mix of L1 and L2 regularization\n",
                "}\n",
                "\n",
                "# Set the random search hyperparameterization method parameters\n",
                "random_search_params = {\n",
                "    \"param_distributions\": param_dist,\n",
                "    \"scoring\": \"neg_mean_squared_error\",  # Suitable for regression\n",
                "    \"random_state\": 0,\n",
                "    \"n_jobs\": -1,\n",
                "    \"cv\": k_folds,\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train models with all A647 or GOLD features\n",
                "\n",
                "Note: Four models in total are created, two for all A647 features (final and shuffled) and two for all GOLD features (final and shuffled)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing all features:   0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing A647 features...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing all features:  50%|\u2588\u2588\u2588\u2588\u2588     | 1/2 [06:55<06:55, 415.70s/it]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing GOLD features...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                       "
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "All models for both combined A647 and GOLD features have been trained and tuned!\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r"
                    ]
                }
            ],
            "source": [
                "# Suppress all warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "# List of feature sets to iterate per stain\n",
                "stain_feature_sets = [(\"A647\", a647_features), (\"GOLD\", gold_features)]\n",
                "\n",
                "# Loop through each staim feature set\n",
                "for stain_name, feature_list in tqdm(stain_feature_sets, desc=\"Processing all features\", leave=False):\n",
                "    # Dynamically print progress\n",
                "    tqdm.write(f\"Processing {stain_name} features...\")\n",
                "\n",
                "    # Combine features into a matrix for the current feature set\n",
                "    y_matrix = training_df[feature_list]\n",
                "    \n",
                "    # Initialize the model\n",
                "    logreg = ElasticNet(**elasticnet_params)\n",
                "\n",
                "    # Initialize random search and fit model\n",
                "    random_search = RandomizedSearchCV(logreg, **random_search_params)\n",
                "    random_search.fit(X, y_matrix)  # Fit using all features as y\n",
                "\n",
                "    # Save the tuned model for the current feature set\n",
                "    model_filename = all_features_dir / f\"combined_{stain_name}_tuned_model.joblib\"\n",
                "    joblib.dump(random_search.best_estimator_, model_filename)\n",
                "\n",
                "    random_search_shuffled = RandomizedSearchCV(logreg, **random_search_params)\n",
                "    random_search_shuffled.fit(X_shuffled, y_matrix)  # Fit on shuffled data\n",
                "\n",
                "    # Save the shuffled tuned model for the current feature set\n",
                "    shuffled_model_filename = all_features_dir / f\"combined_{stain_name}_shuffled_tuned_model.joblib\"\n",
                "    joblib.dump(random_search_shuffled.best_estimator_, shuffled_model_filename)\n",
                "\n",
                "print(\"All models for both combined A647 and GOLD features have been trained and tuned!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train individual A647 models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                           "
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "All A647 models have been trained and tuned!\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r"
                    ]
                }
            ],
            "source": [
                "# Suppress all warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "for a647_feature in tqdm(a647_features, desc=\"Processing A647 Features\", leave=False):\n",
                "    # Set predicted feature\n",
                "    y = training_df[a647_feature]\n",
                "\n",
                "    # Train regular model with hyperparameter tuning\n",
                "    logreg = ElasticNet(**elasticnet_params)\n",
                "\n",
                "    # Initialize random search and fit model\n",
                "    random_search = RandomizedSearchCV(logreg, **random_search_params)\n",
                "    random_search.fit(X, y)\n",
                "\n",
                "    # Save the tuned model\n",
                "    model_filename = final_dir / f\"{a647_feature}_tuned_model.joblib\"\n",
                "    joblib.dump(random_search.best_estimator_, model_filename)\n",
                "\n",
                "    random_search_shuffled = RandomizedSearchCV(logreg, **random_search_params)\n",
                "    random_search_shuffled.fit(X_shuffled, y)\n",
                "\n",
                "    # Save the shuffled tuned model\n",
                "    shuffled_model_filename = (\n",
                "        shuffled_dir / f\"{a647_feature}_shuffled_tuned_model.joblib\"\n",
                "    )\n",
                "    joblib.dump(random_search_shuffled.best_estimator_, shuffled_model_filename)\n",
                "\n",
                "print(\"All A647 models have been trained and tuned!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train individual GOLD models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                           "
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "All GOLD models have been trained and tuned!\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\r"
                    ]
                }
            ],
            "source": [
                "for gold_feature in tqdm(gold_features, desc=\"Processing GOLD Features\", leave=False):\n",
                "    y = training_df[gold_feature]\n",
                "\n",
                "    # Train regular model with hyperparameter tuning\n",
                "    logreg = ElasticNet(**elasticnet_params)\n",
                "\n",
                "    # Initialize random search\n",
                "    random_search = RandomizedSearchCV(logreg, **random_search_params)\n",
                "    random_search.fit(X, y)\n",
                "\n",
                "    # Save the tuned model\n",
                "    model_filename = final_dir / f\"{gold_feature}_tuned_model.joblib\"\n",
                "    joblib.dump(random_search.best_estimator_, model_filename)\n",
                "\n",
                "    random_search_shuffled = RandomizedSearchCV(logreg, **random_search_params)\n",
                "    random_search_shuffled.fit(X_shuffled, y)\n",
                "\n",
                "    # Save the shuffled tuned model\n",
                "    shuffled_model_filename = (\n",
                "        shuffled_dir / f\"{gold_feature}_shuffled_tuned_model.joblib\"\n",
                "    )\n",
                "    joblib.dump(random_search_shuffled.best_estimator_, shuffled_model_filename)\n",
                "\n",
                "print(\"All GOLD models have been trained and tuned!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
